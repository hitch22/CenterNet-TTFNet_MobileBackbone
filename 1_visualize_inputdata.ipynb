{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import json\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import cv2\n",
    "from utils_train.Encoder import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[_tfrecords], dataset_info = tfds.load(name=\"coco/2017\", split=[\"train\"], with_info=True, shuffle_files=True)\n",
    "for samples in _tfrecords:\n",
    "    image = samples[\"image\"]\n",
    "    originalShape = tf.shape(image)[:2]\n",
    "    classes = tf.cast(samples[\"objects\"][\"label\"], dtype=tf.int32)\n",
    "    bbox_gt = samples[\"objects\"][\"bbox\"]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"MobileNetV3_FPN_CenterNet\"\n",
    "\n",
    "model_dir = \"checkpoints/\"\n",
    "modelPart = modelName.split(\"_\")\n",
    "\n",
    "with open(os.path.join(\"model\", \"0_Config\", modelName+\".json\"), \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "config['modelName'] = modelName\n",
    "config['training_config']['num_classes'] = 80\n",
    "\n",
    "\n",
    "##########\n",
    "ids = tf.argsort(classes)\n",
    "classes = tf.gather(classes, ids)\n",
    "bboxes2 = tf.gather(bbox_gt, ids)\n",
    "##########\n",
    "\n",
    "le = LabelEncoder(config=config)\n",
    "target = le._encode_sample(bboxes2, classes)\n",
    "\n",
    "hm  = target[..., :80]\n",
    "box  = target[..., 80:84]\n",
    "rW  = target[..., 84:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.random.rand(80, 3)*255\n",
    "\n",
    "original_img = image.numpy()\n",
    "for bbox, cls in zip(bbox_gt, classes):\n",
    "    y1, x1, y2, x2 = bbox\n",
    "    x1 = int(x1*image.shape[1])\n",
    "    x2 = int(x2*image.shape[1])\n",
    "    y1 = int(y1*image.shape[0])\n",
    "    y2 = int(y2*image.shape[0])\n",
    "\n",
    "    _text = '{}'.format(int(cls.numpy()))\n",
    "    cv2.putText(original_img, _text, (x1,y1+10), cv2.FONT_HERSHEY_COMPLEX, 0.5, colors[int(cls.numpy())], thickness=1, lineType=cv2.LINE_AA)\n",
    "    cv2.rectangle(original_img, (x1, y1), (x2, y2), (colors[int(cls.numpy())]), 1)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(cv2.resize(original_img, [480, 480]))\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(tf.reduce_max(hm, -1).numpy(), cmap='viridis')\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "box_np = box.numpy()\n",
    "plt.imshow(box_np)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "rW_show = rW.numpy()\n",
    "plt.imshow(rW_show)\n",
    "\n",
    "a1 = tf.cast(hm==1, tf.float32)\n",
    "print(\"Num of Positives: \", tf.reduce_sum(a1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('w1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edd95acf9ab06b1ecf423b431b914fca015df3a9e640117d0d3acee71022bc47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
