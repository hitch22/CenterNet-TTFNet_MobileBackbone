{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model.ModelBuilder import ModelBuilder\n",
    "from utils_train.customLoss import CenterNetLoss\n",
    "from utils_train.Datagenerator import Dataset_COCO\n",
    "from utils_train.customOptimizer import GCSGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.optimizer.set_jit(\"autoclustering\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRFind(tf.keras.callbacks.Callback): \n",
    "    def __init__(self, min_lr, max_lr, n_rounds): \n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_up = (max_lr / min_lr) ** (1 / n_rounds)\n",
    "        self.lrs = []\n",
    "        self.losses = []\n",
    "     \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.weights = self.model.get_weights()\n",
    "        self.model.optimizer.lr = self.min_lr\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.lrs.append(self.model.optimizer.lr.numpy())\n",
    "        self.losses.append(logs[\"TotalL\"])\n",
    "        self.model.optimizer.lr = self.model.optimizer.lr * self.step_up\n",
    "        if self.model.optimizer.lr > self.max_lr:\n",
    "            self.model.stop_training = True\n",
    "        \n",
    "    def on_train_end(self, logs=None):\n",
    "        self.model.set_weights(self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = \"MobileNetV3_FPN_TTFNet\"\n",
    "\n",
    "with open(os.path.join(\"model/0_Config\", modelName+\".json\"), \"r\") as config_file:\n",
    "    config = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['training_config']['num_classes'] = 80\n",
    "train_dataset = Dataset_COCO(config, mode = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "lr_finder_steps = 400\n",
    "lr_find = LRFind(1e-6, 1e1, lr_finder_steps)\n",
    "\n",
    "model = ModelBuilder(config = config)\n",
    "optimizer = GCSGD(learning_rate = 1e-1, momentum=0.9, nesterov=False)\n",
    "optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n",
    "tf.keras.mixed_precision.set_global_policy(tf.keras.mixed_precision.Policy('mixed_float16'))\n",
    "model.compile(loss=CenterNetLoss(config), optimizer=optimizer, weighted_metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_dataset.dataset,\n",
    "    steps_per_epoch=lr_finder_steps,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[lr_find]\n",
    ")\n",
    "\n",
    "plt.plot(lr_find.lrs, lr_find.losses)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('w1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edd95acf9ab06b1ecf423b431b914fca015df3a9e640117d0d3acee71022bc47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
